\chapter{Background}
Apart from general text content, structured information is also widely contained by digital document. 
Among these, a lot of mathematical content are represented, they are primarily using \LaTeX, which is a rich structural markup language. 
Information Retrieval on those structured data in mathematics language is not as well-studied or exhaustively covered as that is in general text IR research. 
To better search mathematical content can be significantly meaningful in terms of extending our border on information retrieval.


However, the structured sense of mathematical language, as well as many its semantic properties (see section~\ref{measure_sim}), makes general text retrieval models deficient to provide good search results. 
This is because some fundamental differences between mathematical language and general text.
Through this paper, we have made our efforts to tackle some of the problems we are having to search mathematical language. 
Some of the ideas used in this paper that deals with "tree structured" data can be generalized and potentially applied to other fields of structured data retrieval. 

\section{Math IR Domains}

Mathematical information involves a wide spectrum of topics, 
\cite{goodsurvey} gives a comprehensive review on mathematical IR researches.
We are of cause not focusing on every aspect in mathematical information retrieval. 
It is good to clarify our concentration in this paper here by first listing a set of concentrations in the related research area and define our target field of study.

\pagebreak
Listed here, are considered three major topics for mathematical information retrieval:

\begin{enumerate}
\item Boolean or Similarity Search
\item Math Detection and Recognition
\item Evaluation, Derivation and Calculation
\end{enumerate}

Boolean/Similarity search finds or ranks mathematical expressions against a query. 
They define the criteria of matching expressions or dimensions of similarity between two expressions.
This is analogy to the boolean or similarity search of general text search engines,
except the query and document may contain mathematical expressions. 
Some search engines deal with only formula (e.g. 
SearchOnMath~\footnote{\url{http://searchonmath.com}},
Uniquation~\footnote{\url{http://uniquation.com/en}}
and 
Tangent~\footnote{\url{http://saskatoon.cs.rit.edu/tangent/random}}
) 
and some math-aware search engines (e.g.
WolframAlpha~\footnote{\url{https://www.wolframalpha.com/}} and 
Zentralblatt math from MathWebSearch~\footnote{\url{http://search.mathweb.org/zbl/}}
)
are able to search query with mixed text and mathematical formula.
These search engines can be useful in many ways, for example, student may utilize it to know which identity can be applied to a formulae in order to give a proof of that formulae.
This is also the area where we focus in this paper. 

Digital mathematical content document can also be in an image format (e.g. a handwritten formula), topics on retrieving information in these image requires detection and recognition of their visual features (texture, outline, shape etc.).

Also, because the nature of mathematical language, a query (e.g. an algebra expression) can potentially derived into alternate forms, or calculated and evaluated into a value. 
These potentially require a system to handle symbolic or numeric calculation, or even a good knowledge of derivation rules implied by different mathematical expression. 
Those numeric search engines
(e.g. computational engine \textit{Symbolab}~\footnote{Symbolab Web Search: \url{http://www.symbolab.com}} and WolframAlpha)
can help evaluate mathematical expressions and reveal the deeper information contained from those expressions.

Besides the first three concentrations, there are many other topics. Knowledge mining, for example, will need deeper level of understanding on math language. A typical goal of this topic is to give a solution or answer based on all the document information retrieved. e.g. ``Find an article related to the \textit{Four Color Theorem}"~\cite{ntcirtopic}.

These topics somehow overlap in some cases, for example, some derivation can be used to better assess the similarity between math formulae, e.g. $\dfrac{a + b}{c}$ and $\dfrac{a}{c} + \dfrac{b}{c}$ should be considered as relevant because their equivalent form of representation.
Similarly, mathematical knowledge is required to understand the same meaning (thus high similarity) between $ \dbinom n 1 $ and $C_n^1$.
So boolean or similarity search possibly involves a level of understanding on mathematical language. 
However, we are not going to include these problems into our research domain, instead, this paper addresses mathematical expression similarity from only structural and symbolic perspectives.

\section{Issues in Measuring Similarity}
\label{measure_sim}
Unlike general text content, mathematical language, by its nature, has many differences from other textual documents, there are a number of new problems in measuring mathematical expression similarity. 
Even without caring about the possible derivations and high level knowledge inference, there are still a set of new problems for measuring mathematical similarity.

Firstly, the differences between mathematical expressions should be captured in a cooperative manner in order to measure similarity,
because only respecting symbolic information is not sufficient in mathematical language.
To illustrate this point, we know that
$ax+(b+c)$ in most cases is not equivalent to $(a+b)x+c$ although they have the same set of symbols, because the different structure represents a different semantic meaning.
And the order of tokens in math expression can be commutative in some cases but not always, for example, commutative property in math makes $a+b=b+c$ for addition operation, but on the other hand $\dfrac a b$ is most likely not equivalent to $\dfrac b a$.
These characteristics make many general text search methods (e.g. \textit{bag of words} model, \textit{tf-idf} weighting) inadequate.  
Moreover, symbols can be used interchangeably to represent the same meaning, e.g. $a^2+b^2=c^2$ and $x^2+y^2=z^2$. 
However, interchanging symbols does not always preserve mathematical semantics, changes of symbols in expression preserve more syntactic similarity when changes are made by substitution, e.g. Given query $x(1+x)$, expression $a(1+a)$ are considered more relevant than $a(1+b)$. 

Secondly, how we evaluate structural similarity between expressions is a question. A complete query may structurally be a part of a document, or only some parts of a query match somewhere in a document expression.
In cases when a set of matches occur within some measure of ``distance", we may consider them to contribute similarity as a whole, but when matches occur ``far away" for a query expression, then under the semantic implication of mathematics, they probably will not contribute the similarity degree in any way.
We need metrics to score these similarity under certain rules for relevance assessments. 

Lastly, when trying to capture more semantic information from expressions, we can improve our measurement on similarity but it may introduce more ambiguity. 
For example, semantically incorrect math markups in document, e.g. using ``sin" in \LaTeX\ markup instead of macro ``\textbackslash sin", will make it difficult to tell whether it is a product of three symbols or a \textit{sine} function if we want to capture their semantical meaning in such a depth. 
And depending on what level of semantical meaning we want to capture, ambiguity cases can be different. 
Consider $f(2x+1)$, if we want to know if $f$ is a function rather than a variable, the only possibility is looking for its contexts, but we can nevertheless always think of it as a product without losing the possibility to search similar expression like $f(1 + 2y)$, the same way goes reciprocal $a^{-1}$ and inverse function $f^{-1}$. 
Most often, even if no semantic ambiguity occurs, efforts are needed to capture some semantical meanings. e.g. In $\sin 2 \pi$, it is not easy to figure out,
 without a knowledge on trigonometric function convention, that $2 \pi$ is the subordinative of sine function.


\section{Related Work}
\label{relatedwork}
Boolean or similarity search for mathematical content is not a new topic, conference in this topic is getting increasingly research attention and the proposed systems have progressed considerably~\cite{ov}. 
A variety of approaches have already emerged in an early timeline~\cite{egomath13}, but we can nevertheless categorize them into several different ideas.
\cite{WikiMirs13,symbolpairs15,Youssef14} use the same way to classify them into text-based and tree-based (structure-based),
here we decide to follow the same classification method and give an overview on those different ideas.

\subsection{Text-based methods}
Many researchers are utilizing existing models to deal with mathematical search, and use texted-based approaches to capture structural information on top of matured text search engine and tools (such as \textit{Apache Lucene}). 

DLMF project from NIST~\cite{Youssef03} uses ``flattening process" to convert math to textualized terms, and normalize them into \textit{sorted parse tree normal form} which creates an unique form for all possible orders of nodes among associative and commutative operators. 
Then further introduces serialization and scoping to stack terms~\cite{Youssef05}, trying to capture structure information by using text-IR based systems that supports phrase search. 
Similar idea is also used by \cite{extending08}, expressions are also augmented for various possible representations, but variables are also replaced and normalized, but they are using postfix notation, allows to search subexpressions without knowing the operator between them.  
MIaS system~\cite{mias11a,mias11,mias:thesis}, like the methods above, are also trying to reorder commutative operations, normalize variables and constance numbers into unified symbols, doing augmentation in a similar fashion. 
It indexes expressions and subexpressions from all depth levels. The system is able to discriminate and assign different weight based on their generalization level, and place emphasis on that a match in a complex expression is assigned higher weight~\cite{mias:thesis}.

Augmentation usually consists a storage demand for combination of both symbols (e.g. \textit{a} and \textit{b}) and unified items (\textit{id, const}) in different levels, in order to capture both symbolic information and structure information. Thus implies complex expressions with many commutative operators will cost inevitably larger storage space, the benefits of capturing expression variances will be overshadowed.

Although named as structured-based approach, \cite{not-really-struct} is using \textit{longest common subsequence} algorithm to capture structure information (in an unified \textit{preprocessed string} and a \textit{level string}). The method takes $O(n^2)$ complexity for comparing a pair of formulae, and no index method is proposed. Therefore is not feasible to efficiently apply to a large collection.
The Mathdex search engine~\cite{queryf_datan07}, from another perspective, uses query likelihood approach~\cite{iir} to estimate how likely the document will generate the query expression.
Math GO!~\cite{Adeel_mathgo} is another system advances some transitional method to better search math content. It tries to find all the symbols and map formula pattern to pattern name keywords (like \textit{matrix} or \textit{root}), and proposes to replace term frequency by co-occurrence of a term with other terms.

\subsection{Structure-based methods}
What text-based methods share in common is they are converting math language symbols to linear tokens, the intrinsic defect when using a bag of words to replace structured information will make conversion process lose considerable information or cause storage-inefficiency.
In order to cope with the problems from text-based approach, structure-based methods generally generate intermediate tree structure, and use these information to index or search.

\subsubsection*{Term Indexing}
Whelp~\cite{whelp04} and MathWebSearch (MWS) directed by Kohlhase~\cite{Kohlhase06,Kohlhase0p4,Kohlhase0p5}, are one of the notable structure-based ones which are derived from \textit{automatic theorem proving} and \textit{unification theory}~\cite{AIbook}. The system of MWS uses \textit{term indexing}~\cite{graf96} in a \textit{substitution tree index}~\cite{graf96} to to minimize access time and storage. Because the subexpression is not easy to search using substitution tree, MWS indexes all sub-terms, but the increased index size remains manageable~\cite{Kohlhase06}. However, their index relies heavily on RAM memory, 
the considerable RAM resource usage (170GB reportedly~\cite{Kohlhase0p5}) makes it have to scale to accommodate $72\%$ papers on arXiv. 

\subsubsection*{Leaf-root path}
\label{leafrootmethod}
\cite{MathMLleafroot} uses leaf to root XML path in a MathML object to represent math formula. When efficiency is considered, it only indexes the first and deepest path (to indicate how a formula is started and presumably the most characteristic part of a formula); 
when user wants to obtain the perfect-match result, it indexes all the MathML object leaf-root path. The boolean search is performed by giving all the paths match with those of the search query. 
\cite{sefobyfo} further develops with incorporation of previous method using breath-first search, to add sibling nodes information into index and have achieved better effectiveness.

Very similar idea is proposed by \cite{signifjap} and used in \cite{signfused}. The latter transform MathML to an ``apply free" markup from which the leaf-root path are extracted. Leaf-root path is also used to evaluate similarity between two expressions in MathML.

\subsubsection*{Symbol layout tree}
A \textit{symbol layout tree}~\cite{symbollayout12} (SLT) or \textit{presentation tree}~\cite{WikiMirs13} describes geometric layouts of mathematical expression. 
WikiMirs~\cite{WikiMirs13} uses two templates to parse \LaTeX\  markup with two typical operator terms: explicit ones (``\bbb frac", ``\bbb sqrt", etc.) and implicit ones (``$+$", ``$\div$", etc.) to form a presentation tree, then extracts original terms and generalized terms from normalized presentation tree, to provide the flexibility of both fuzzy and exact search. 
\cite{symbollayout12} uses symbol layout tree as a kind of substitution tree, each branch in the tree represents a binding chain for variables, and every child node is an instance of its parent for a generalized term. 
They introduce \textit{baseline size} to help group similar expressions together in their substitution SLT in order to decrease tree branch factor, however, this makes a single substitution variable not able to match multiple terms along the baseline. 
Also their implementation makes it unable to index certain formula (e.g. a left-side superscript) and have to generate many queries (e.g. all possible format variations and sub-expressions etc.) for a single query at the time of search.
Later \cite{symbolpairs15,symbolpair15:2} have developed a \textit{symbol pairs} idea to capture a relative position information between symbol pairs. Due to the many possible combinations of symbol pairs in a complex math expression, the storage cost is intrinsically large. However, the key-value storage style will be suitable for fast lookup (e.g. HASH). 

\subsubsection*{Other structure-based methods}
A novel indexing scheme and lookup algorithm is proposed by \cite{newretrievalsystem}, its index has hash signature for each subtree because they have observed a lot of common subtree structure occur in math formula collection. This idea will result in a slower index growth. Their lookup algorithm supports wildcards, and performs a boolean match test. Although their lookup time is generally below 700ms, the index size where query lookup time is tested is unclear, but presumably no greater than 70,000 expressions.
By constructing a DOM tree, \cite{DOMextraction} extracts semantic keywords, structure descriptions to indicate subordinative relationship in a string format. The similarity is calculated using normalized tf-idf vector (trained by clustering algorithms) by dot product. Although the final index is generated from text, promising results have been achieved.  
Tree edit distance is adopted by \cite{editdisXML11}, it tries to overcome the bad time complexity of original algorithm by summarizing and using a structure-preserving compromised edit distance algorithm. Although the result shows query processing time is long but it is reduced to average 0.8 seconds by applying with an early termination algorithm along with a distance cache~\cite{editdisXML13}.

\subsection{Other related work}
There are a number of articles trying to use image to assess math expression similarity. \cite{imageb11} compares their image-based approach using connected component-based feature vector with a proposed text-based method, reported precision@k values are low, but the potential for this method to be combined with shape representations or other features will potentially improve it and make it valuable for searching mathematical expressions in image format. 
\cite{handwrite} uses \mbox{X-Y} tree to cuts the page in vertical and horizontal directions alternatively, in order to retrieve math symbols from images. 

A lattice-based approach~\cite{lattice} builds formal concept based on selected feature sets of each formula. The ranking is calculated by the distances from query in the lattice map when the query is inserted. 

\subsection{Performance Review}
In the review of many related past research in section~\ref{relatedwork}, we find the combination of state-of-art general text search engine (i.e. \textit{Apache Lucene}) with the efforts to augment expressions by permutation and unification to satisfy the needs of mathematical search have achieved a good result in different metrics of evaluation: 
The text-based system of MIaS over-performs those of structure-based and ranked the first in four out of six measurement in NTCIR-11 conference~\cite{NTCIR11res}. 
However, structure-based method such as symbol pairs proposed in \cite{symbolpairs15,symbolpair15:2} also gets a competitive result~\cite{NTCIR11res}. 

Although text-based methods have achieved relatively better effectiveness, their commonly adoption of augmentation makes it expensive in terms of hardware storage. 
On the other hand, structure-based method has the merit to best capture semantic information of a typical mathematical expression, thus still has the potential to further improve effectiveness given the fact that the tools and theory behind test-based methods are already mature and have been developed for decades.
