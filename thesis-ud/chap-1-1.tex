\chapter{Related Work}
\label{relatedwork}
Boolean or similarity search for mathematical content is not a new topic, conference in this topic is getting increasingly research attention and the proposed systems have progressed considerably~\cite{ov}. 
A variety of approaches have already emerged in an early timeline~\cite{egomath13}, but we can nevertheless categorize them into several different ideas.
\cite{WikiMirs13,symbolpairs15,Youssef14} use the same way to classify them into text-based and tree-based (structure-based),
here we decide to follow the same classification method and give an overview on those different ideas.

\section{Text-based methods}
Many researchers are utilizing existing models to deal with mathematical search, and use texted-based approaches to capture structural information on top of matured text search engine and tools (such as \textit{Apache Lucene}). 

DLMF project from NIST~\cite{Youssef03} uses ``flattening process" to convert math to textualized terms, and normalize them into \textit{sorted parse tree normal form} which creates an unique form for all possible orders of nodes among associative and commutative operators. 
Then further introduces serialization and scoping to stack terms~\cite{Youssef05}, trying to capture structure information by using text-IR based systems that supports phrase search. 
Similar idea is also used by \cite{extending08}, expressions are also augmented for various possible representations, but variables are also replaced and normalized, but they are using postfix notation, allows to search subexpressions without knowing the operator between them.  
MIaS system~\cite{mias11a,mias11,mias:thesis}, like the methods above, are also trying to reorder commutative operations, normalize variables and constance numbers into unified symbols, doing augmentation in a similar fashion. 
It indexes expressions and subexpressions from all depth levels. The system is able to discriminate and assign different weight based on their generalization level, and place emphasis on that a match in a complex expression is assigned higher weight~\cite{mias:thesis}.

Augmentation usually consists a storage demand for combination of both symbols (e.g. \textit{a} and \textit{b}) and unified items (\textit{id, const}) in different levels, in order to capture both symbolic information and structure information. Thus implies complex expressions with many commutative operators will cost inevitably larger storage space, the benefits of capturing expression variances will be overshadowed.

Although named as structured-based approach, \cite{not-really-struct} is using \textit{longest common subsequence} algorithm to capture structure information (in an unified \textit{preprocessed string} and a \textit{level string}). The method takes $O(n^2)$ complexity for comparing a pair of formulae, and no index method is proposed. Therefore is not feasible to efficiently apply to a large collection.
The Mathdex search engine~\cite{queryf_datan07}, from another perspective, uses query likelihood approach~\cite{iir} to estimate how likely the document will generate the query expression.
Math GO!~\cite{Adeel_mathgo} is another system advances some transitional method to better search math content. It tries to find all the symbols and map formula pattern to pattern name keywords (like \textit{matrix} or \textit{root}), and proposes to replace term frequency by co-occurrence of a term with other terms.

\section{Structure-based methods}
\label{Structure-based}
What text-based methods share in common is they are converting math language symbols to linear tokens, the intrinsic defect when using a bag of words to replace structured information will make conversion process lose considerable information or cause storage-inefficiency.
In order to cope with the problems from text-based approach, structure-based methods generally generate intermediate tree structure, and use these information to index or search.

\subsection*{Term Indexing}
Whelp~\cite{whelp04} and MathWebSearch (MWS) directed by Kohlhase~\cite{Kohlhase06,Kohlhase0p4,Kohlhase0p5}, are one of the notable structure-based ones which are derived from \textit{automatic theorem proving} and \textit{unification theory}~\cite{AIbook}. The system of MWS uses \textit{term indexing}~\cite{graf96} in a \textit{substitution tree index}~\cite{graf96} to to minimize access time and storage. Because the subexpression is not easy to search using substitution tree, MWS indexes all sub-terms, but the increased index size remains manageable~\cite{Kohlhase06}. However, their index relies heavily on RAM memory, 
the considerable RAM resource usage (170GB reportedly~\cite{Kohlhase0p5}) makes it have to scale to accommodate $72\%$ papers on arXiv. 

\subsubsection*{Leaf-root path}
\label{leafrootmethod}
\cite{MathMLleafroot} uses leaf to root XML path in a MathML object to represent math formula. When efficiency is considered, it only indexes the first and deepest path (to indicate how a formula is started and presumably the most characteristic part of a formula); 
when user wants to obtain the perfect-match result, it indexes all the MathML object leaf-root path. The boolean search is performed by giving all the paths match with those of the search query. 
\cite{sefobyfo} further develops with incorporation of previous method using breath-first search, to add sibling nodes information into index and have achieved better effectiveness.

Very similar idea is proposed by \cite{signifjap} and used in \cite{signfused}. The latter transform MathML to an ``apply free" markup from which the leaf-root path are extracted. Leaf-root path is also used to evaluate similarity between two expressions in MathML.

\subsection*{Symbol layout tree}
A \textit{symbol layout tree}~\cite{symbollayout12} (SLT) or \textit{presentation tree}~\cite{WikiMirs13} describes geometric layouts of mathematical expression. 
WikiMirs~\cite{WikiMirs13} uses two templates to parse \LaTeX\  markup with two typical operator terms: explicit ones (``\bbb frac", ``\bbb sqrt", etc.) and implicit ones (``$+$", ``$\div$", etc.) to form a presentation tree, then extracts original terms and generalized terms from normalized presentation tree, to provide the flexibility of both fuzzy and exact search. 
\cite{symbollayout12} uses symbol layout tree as a kind of substitution tree, each branch in the tree represents a binding chain for variables, and every child node is an instance of its parent for a generalized term. 
They introduce \textit{baseline size} to help group similar expressions together in their substitution SLT in order to decrease tree branch factor, however, this makes a single substitution variable not able to match multiple terms along the baseline. 
Also their implementation makes it unable to index certain formula (e.g. a left-side superscript) and have to generate many queries (e.g. all possible format variations and sub-expressions etc.) for a single query at the time of search.
Later \cite{symbolpairs15,symbolpair15:2} have developed a \textit{symbol pairs} idea to capture a relative position information between symbol pairs. Due to the many possible combinations of symbol pairs in a complex math expression, the storage cost is intrinsically large. However, the key-value storage style will be suitable for fast lookup (e.g. HASH). 

\subsection*{Other structure-based methods}
A novel indexing scheme and lookup algorithm is proposed by \cite{newretrievalsystem}, its index has hash signature for each subtree because they have observed a lot of common subtree structure occur in math formula collection. This idea will result in a slower index growth. Their lookup algorithm supports wildcards, and performs a boolean match test. Although their lookup time is generally below 700ms, the index size where query lookup time is tested is unclear, but presumably no greater than 70,000 expressions.
By constructing a DOM tree, \cite{DOMextraction} extracts semantic keywords, structure descriptions to indicate subordinative relationship in a string format. The similarity is calculated using normalized tf-idf vector (trained by clustering algorithms) by dot product. Although the final index is generated from text, promising results have been achieved.  
Tree edit distance is adopted by \cite{editdisXML11}, it tries to overcome the bad time complexity of original algorithm by summarizing and using a structure-preserving compromised edit distance algorithm. Although the result shows query processing time is long but it is reduced to average 0.8 seconds by applying with an early termination algorithm along with a distance cache~\cite{editdisXML13}.

\section{Other related work}
There are a number of articles trying to use image to assess math expression similarity. \cite{imageb11} compares their image-based approach using connected component-based feature vector with a proposed text-based method, reported precision@k values are low, but the potential for this method to be combined with shape representations or other features will potentially improve it and make it valuable for searching mathematical expressions in image format. 
\cite{handwrite} uses \mbox{X-Y} tree to cuts the page in vertical and horizontal directions alternatively, in order to retrieve math symbols from images. 

A lattice-based approach~\cite{lattice} builds formal concept based on selected feature sets of each formula. The ranking is calculated by the distances from query in the lattice map when the query is inserted. 

\section{Performance Review}
In the review of many related past research in section~\ref{relatedwork}, we find the combination of state-of-art general text search engine (i.e. \textit{Apache Lucene}) with the efforts to augment expressions by permutation and unification to satisfy the needs of mathematical search have achieved a good result in different metrics of evaluation: 
The text-based system of MIaS over-performs those of structure-based and ranked the first in four out of six measurement in NTCIR-11 conference~\cite{NTCIR11res}. 
However, structure-based method such as symbol pairs proposed in \cite{symbolpairs15,symbolpair15:2} also gets a competitive result~\cite{NTCIR11res}. 

Although text-based methods have achieved relatively better effectiveness, their commonly adoption of augmentation makes it expensive in terms of hardware storage. 
On the other hand, structure-based method has the merit to best capture semantic information of a typical mathematical expression, thus still has the potential to further improve effectiveness given the fact that the tools and theory behind test-based methods are already mature and have been developed for decades.
